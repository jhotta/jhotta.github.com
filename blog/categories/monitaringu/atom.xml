<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: モニターリング | Etizolam]]></title>
  <link href="http://jhotta.github.io/blog/categories/monitaringu/atom.xml" rel="self"/>
  <link href="http://jhotta.github.io/"/>
  <updated>2014-06-10T18:37:13+09:00</updated>
  <id>http://jhotta.github.io/</id>
  <author>
    <name><![CDATA[@jhotta]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[モニターリングサービスのDatadogを使ってDockerをモニターリング&管理]]></title>
    <link href="http://jhotta.github.io/blog/2014/06/10/monitoring-docker-with-the-datadog/"/>
    <updated>2014-06-10T10:50:00+09:00</updated>
    <id>http://jhotta.github.io/blog/2014/06/10/monitoring-docker-with-the-datadog</id>
    <content type="html"><![CDATA[<p>「今日は、<a href="http://www.dockercon.com/">dockercon14</a>が、サンフランシスコで開催されているな〜」と思っていたら、Datadog blogからもDocker関連の面白い記事が掲載されました。</p>

<p>Datadog agent 4.3.1をDockerホストOS上で起動し、他のアプリと同じようにIntegration用のYAMLファイルを設定することでDcoker内の各コンテナの状態をモニターリングできるということです。</p>

<p><a href="https://www.datadoghq.com">Datadog</a>の<a href="https://twitter.com/alq">@alq</a>が「もちろん翻訳してもいいよ〜! (Yes! Of course.)」言ってくれているので、次に日本語で同記事を転載します。</p>

<h2>Monitor Docker with Datadog</h2>

<p><a href="https://www.datadoghq.com/2014/06/monitor-docker-datadog/">Monitor Docker with Datadog(原文)</a></p>

<p>Docker is an emerging platform to build and deploy software using lightweight, pared-down virtual machines known as containers. By delivering easy-to-provision recipes for developers and bit-for-bit compatibility between environments, Docker is a popular solution to solve continuous delivery in modern infrastructure.</p>

<p><a href="http://www.docker.com/">Docker</a>は、既存の仮想環境から贅肉を削ぎ落とし軽量化したLinuxコンテナという仕組みを使用し、ソフトウェアシステムを構築&amp;展開するための新たなプラットフォームです。Dockerは、アプリ開発者に簡単にプロビジョニングできるレシピを提供することと環境間の再現性を上げることで、現代インフラでの継続的デリバリーを実現する最も人気のある方法になりました。</p>

<p>Like virtual machines before them, containers require a new monitoring approach. Luckily, if you are a Datadog user, you can now take advantage of our newest integration: Docker.</p>

<p>従前の仮想マシンと同様に、Linuxコンテナでも新しい監視アプローチが必要になります。Datadogユーザーであれば幸いなことに、最新のDocker Integrationの恩恵を受けることができます。</p>

<p>With our Docker integration you can monitor containers by running version 4.3.1 of the Datadog agent. The integration configuration is, like all other agent-based integrations, a simple YAML file.</p>

<p>バージョン4.3.1の<a href="http://docs.datadoghq.com/guides/basic_agent_usage/">Datadog agent</a>を導入することで、Docker Integrationを使ってコンテナを監視することができるようになります。
Docker Integrationの設定方法は、今まであった他のアプリケーションのIntegrationと同じように簡単な<a href="https://github.com/DataDog/dd-agent/blob/master/conf.d/docker.yaml.example">YAMLファイル形式</a>になっています。</p>

<h3>How Docker monitoring works</h3>

<p>The simplest way to monitor Docker containers is to run the Datadog Agent on the host, where it can access container statistics. This is especially true if you are deploying Docker on existing, full-fledged Host OSes, along existing applications such as databases.</p>

<p>Dcokerコンテナを監視するための最も簡単な方法は、コンテナのスタティック情報にアクセスできるホスト上でDatadog Agentを実行することです。本格的なホストOSにデータベースなどの既存のアプリケーションと共にDockerを展開するなら、尚更この方法は有効です。</p>

<p><img class="center" src="/images/blog-images/DockerImage1.png" width="400" height="400" title="&lsquo;Where the agent fits in a Docker environment&rsquo; &lsquo;Where the agent fits in a Docker environment&rsquo;" ></p>

<p>Since Docker uses existing kernel constructs (namespaces and cgroups) in order to run containers, the Datadog Agent uses the native cgroup accounting metrics to gather CPU, memory, network and I/O metrics of the containers every 15 seconds before they are forwarded to Datadog.</p>

<p>Dockerは、コンテナを実行するために既存のカーネル構成体（名前空間とcgroup）を使用しています。
Datadog agentは、このカーネル構造体のcgroupか提供するトリックス(指標)を使ってCPU、メモリ、ネットワーク、15秒ごとのコンテナI/Oの情報を収集し、Datadogに転送しています。</p>

<p><img class="center" src="/images/blog-images/DockerImage2_Screenboard.png" width="800" height="800" title="&lsquo;A Docker ScreenBoard&rsquo; &lsquo;A Docker ScreenBoard&rsquo;" ></p>

<h3>Monitor many containers efficiently with tags</h3>

<p>With easy-to-use, lightweight containers, you will likely dial up several times more running containers than the number of underlying physical or virtual hosts in your infrastructure. How do you then keep track and monitor them without spending time chasing after every single one of them? With tags.</p>

<p>簡単に使用でき軽量なコンテナを使うと、インフラストラクチャ内にある物理マシンまたは仮想ホストの数の数倍のコンテナを起動することになるでしょう。あなたらな、どのように時間をかけずに追跡し又監視しますか?　タグを使っては、どうでしょう!</p>

<p>Tags are the key to monitoring a lot of containers without additional effort. By default, the agent will monitor your containers and turn the Docker “name”, “image” and “command” attributes into a “tag”.</p>

<p>追加の努力をせずに大量のコンテナを監視するためには、<a href="http://docs.datadoghq.com/guides/metrics/#tags">タグ付け</a>が有効な解決策です。何もしなくてもDatadog agentは、Dockerの「名前」,「イメージ名」,「コマンド」の属性をタグに追加します。</p>

<p><img class="center" src="/images/blog-images/DockerImage3_tags.png" width="800" height="800" title="&lsquo;Tags&rsquo; &lsquo;Tags&rsquo;" ></p>

<h3>Graph specific metrics with tags</h3>

<p>In Datadog, you define the metrics shown in dashboards and graphs based on one or many tags. This allows you to track specific metrics for many containers in aggregate. Using tags, you can easily create a graph for a metric drawn from all containers running a given image.</p>

<p>Datadogでは、タグの組み合わせに基づいてダッシュボードやグラフに表示するメトリック(指標)を定義することができます。この複数のタグの組み合わせによって統計的に複数のコンテナの特定のメトリックス(指標)を追跡することができるようになります。又タグを使用すると、同じDockerイメージから起動しているコンテナのメトリックス(指標)を手軽にグラフを描くこともできます。</p>

<p>In the example below, we are showing the amount of CPU consumed, broken down by image.</p>

<p>以下の例では、CPUの消費量をDockerイメージの分類で表示しています。</p>

<p><img class="center" src="/images/blog-images/DockerImage4_graph_by_image.png" width="800" height="800" title="&lsquo;Using tags to visualize Docker performance&rsquo; &lsquo;Using tags to visualize Docker performance&rsquo;" ></p>

<h3>Alerts</h3>

<p>Tags are also very useful to define alerts that span clusters of containers. For instance, let us say that you are running a cluster of Redis containers and you want to be alerted when one of the containers is running out of memory.</p>

<p>タグの使用は、コンテナをクラスター化し、そのクラスターにアラートを定義するのに非常に便利です。たとえば、Redisが起動しているコンテナのクラスターを運用中、クラスタ内のどれかのコンテナにメモリの不足が発生した場合に、アラートを受け取るようにしたいとしましょう​​。</p>

<p>Instead of defining one alert per container, you only have to create a multi-alert on the docker.mem.rss metric and Datadog will trigger an alert if any container misbehaves.</p>

<p>各コンテナごとにアラートの定義する代わりに、<code>docker.mem.rss</code>のメトリックス(指標)を基に、<strong>multi-alert</strong>を設定します。Datadogでは、この設定によって任意のコンテナでの誤作動によりアラートを送信することができます。</p>

<p>You can also mix and match tags to express more complex conditions. For instance, you can monitor all Redis containers running the redis2.8 image that run on host alq-docker with a simple tag selection:</p>

<p>又タグは、より複雑な条件を設定するためにタグを組み合わせてマッチングさせることができます。たとえば、簡単なタグ選択により、ホスト名<code>alq-docker</code>上で実行されているDockerイメージ<code>redis2.8</code>のすべてのRedisのコンテナを監視することができます。</p>

<p><img class="center" src="/images/blog-images/DockerImage5-multi-alert.png" width="800" height="800" title="&lsquo;Monitoring all containers&rsquo; &lsquo;Monitoring all containers&rsquo;" ></p>

<h3>Monitor your containers’ lifecycles</h3>

<p>Since containers are designed to be as short-lived (or long-lived) as traditional OS processes, it can be very useful to track particular containers throughout their lifecycles.</p>

<p>コンテナは、伝統的なOSのプロセスのように短期間しか存在しないように設計されています。従って、そのライフサイクルを通して状態を追跡することは非常に重要です。</p>

<p>Much like any other meaningful event in your infrastructure, you can search for Docker container create/start/stop/destroy events using the Events Stream. Simply use “sources:docker” as the search filter.</p>

<p>インフラ内の他の重要な出来事のように、Dockerコンテナのcreate/start/stop/destroy イベントは、Datadogのイベントストリームで検索することができます。<a href="https://www.datadoghq.com/2014/05/filter-datadog-events-stream-pinpoint-events-infrastructure/">検索フィルター</a>で<code>sources:docker</code>と入力し検索するだけです。</p>

<p><img class="center" src="/images/blog-images/DockerImage6_Events.png" width="800" height="800" title="&lsquo;search filter&rsquo; &lsquo;search filter&rsquo;" ></p>

<p>You can also apply the same search to any TimeBoard to visualize Docker container events in the context of Docker and non-Docker metrics. In the following example, we overlay containers starting and stopping over memory and CPU metrics.</p>

<p>更に、Dockerに関連したメトリックス(指標)とそれ以外のメトリック(指標)の検索結果を同一<strong>TimeBoard</strong>に混在させて表示することができます。次の例では、Dockerコンテナの起動と停止と、ホストマシンのメモリとCPUの消費量を同じ<strong>TimeBoard</strong>で表示しています。</p>

<p><img class="center" src="/images/blog-images/DockerImage7_Correlations.png" width="800" height="800" title="&lsquo;Docker metrics &amp; events correlated&rsquo; &lsquo;Docker metrics &amp; events correlated&rsquo;" ></p>

<h3>Explore Docker metrics</h3>

<p>To explore the Docker metrics that are available, you can use the Metrics Explorer in Datadog and type “docker” in the first drop-down.</p>

<p>利用可能なDockerのメトリックス(指標)は、DatadogのMetrics Explorer画面内の最初のドロップダウンメニューで<code>docker</code>と入力することで探索することができます。</p>

<p><img class="center" src="/images/blog-images/DockerImage8_metrics.png" width="800" height="800" title="&lsquo;Explore Docker metrics&rsquo; &lsquo;Explore Docker metrics&rsquo;" ></p>

<p>You can find detailed descriptions about all the metrics in Docker’s Runtime Metrics guide.</p>

<p>これらのメトリックスの詳細に関しては、<a href="http://docs.docker.com/articles/runmetrics/">Docker’s Runtime Metrics guide</a>を参照してください。</p>

<p>If you would like to easily visualize and alert on Docker metrics, try out Datadog for free with a 14-day trial. Metrics for the Docker engine, containers and underlying hosts will be immediately available after installing the Datadog agent.</p>

<p>Dockerのメトリックス(指標)を使って可視化や通知をしたい場合は、14日間の<a href="https://app.datadoghq.com/signup">フリートライアル</a>を試してみてください。Datadog agentをインストールした後、直ちにDockerエンジン、コンテナ、ホストマシンのメトリックス(指標)を監視できるようになります。</p>

<p>by <a href="http://www.linkedin.com/in/alexislequoc">ALEXIS LÊ-QUÔC</a> (CTO &amp; co-founder Datadog, Inc)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Raspberry piにもDatadog Agentをインストールしてみる(後編)]]></title>
    <link href="http://jhotta.github.io/blog/2014/05/13/datadog-on-raspberry-pi-2/"/>
    <updated>2014-05-13T13:40:00+09:00</updated>
    <id>http://jhotta.github.io/blog/2014/05/13/datadog-on-raspberry-pi-2</id>
    <content type="html"><![CDATA[<p><a href="../../../../../blog/2014/04/11/datadog-on-raspberry-pi-1/">Raspberry piにもDatadog Agentをインストールしてみる(前編)</a>でDatadog Agent(以降DD-agent)のインストールと動作は確認できました。
しかし前回のままでは、Raspberry Piの再起動時に次のコマンドでDD-Agentを起動する手作業が残っていました。</p>

<p><code>bash
sudo su
cd /root/.datadog-agent
sh bin/agent start
</code></p>

<p>ここで僕が参考にしたのが、<code>/root/.datadog-agent/bin/agnet</code>です。このスクリプトの<code>start</code>, <code>stop</code>のあたりに注目します。</p>

<p>```bash
case $action in</p>

<pre><code>start)
    if supervisor_running; then
        echo "Supervisor is already running"
        execute_if_supervisor_running start all
        exit 0
    else
        echo "Starting supervisor"
        supervisord -c $SUPERVISOR_CONF_FILE
    fi
    ;;

stop)
    execute_if_supervisor_running stop all
    exit $?
    ;;
</code></pre>

<p>```</p>

<p>…ということで、<a href="http://supervisord.org/">supervisor</a>って何だろうと思いながら、googleで検索すると<a href="http://qiita.com/yushin/items/15f4f90c5663710dbd56">「Supervisorで簡単にデーモン化」</a>みたいなtoolらしいです。そこで対応OSのinit.dでは、supervisorを使わずにDD-Agentが起動しているのかと思いubuntuでinit.d以下のdatadog-agentスクリプトを見てみましたが、ここでも、supervisorを使っていました。</p>

<p>今回は難しいことを考えずに<code>/root/.datadog-agent/bin/agnet</code>の手順を再利用するこにします。startとstopのコード部分で関数として切り出されている部分をshellのコマンドに戻しディレクトリを調整すると次のようなスクリプトになりました。start,stop,restartしかできない簡単なものですがRaspberry Piの起動時に必要な最低限の要件は満たしていると思います。(error処理の観点からは、まだまだな…)</p>

<p>```bash</p>

<h1>! /bin/sh</h1>

<h3>BEGIN INIT INFO</h3>

<h1>Provides: datadog-agent</h1>

<h1>Short-Description: Start and start datadog-agent</h1>

<h1>Description: datadog-agent is the monitoring Agent component for Datadog</h1>

<h1>Required-Start: $remote_fs $syslog</h1>

<h1>Required-Stop: $remote_fs $syslog</h1>

<h1>Default-Start: 2 3 4 5</h1>

<h1>Default-Stop: 0 1 6</h1>

<h3>END INIT INFO</h3>

<p>DD_BASE=&ldquo;/root/.datadog-agent&rdquo;
SOCK_FILE=&ldquo;/root/.datadog-agent/supervisord/agent-supervisor.sock&rdquo;</p>

<p>supervisor_running() {</p>

<pre><code>[ -e $SOCK_FILE ]
</code></pre>

<p>}</p>

<p>case $1 in</p>

<pre><code>start)
    if supervisor_running; then
        echo "Supervisor is already running"
        cd $DD_BASE &amp;&amp; venv/bin/supervisorctl -c supervisord/supervisord.conf start all
        exit 0
    else
        echo "Starting Supervisor"
        cd $DD_BASE &amp;&amp; venv/bin/supervisord -c supervisord/supervisord.conf &amp;
        exit 0
    fi
    ;;

stop)
    cd $DD_BASE &amp;&amp; venv/bin/supervisorctl -c supervisord/supervisord.conf stop all
    exit 0
    ;;

restart)
    cd $DD_BASE &amp;&amp; venv/bin/supervisorctl -c supervisord/supervisord.conf stop all
    cd $DD_BASE &amp;&amp; venv/bin/supervisorctl -c supervisord/supervisord.conf start all
    exit 0
    ;;
</code></pre>

<p>esac
exit 0
```</p>

<p>スクリプト前半のコメントアウトされている部分を詳しく知りたい人は、<a href="https://wiki.debian.org/LSBInitScripts">LSBInitScripts</a>を参考にしてください。個人的には、<code>/etc/init.d/skeleton</code>などを参考にコピペ&amp;編集することにしています。</p>

<p>startの部分でsupervisord.sockの存在確認をしているのは、<code>supervisord</code>がDD-Agentの管理をするため、Raspberry Piの起動時のみにデーモンとして起動して欲しいからです。
起動以降は<code>supervisorctl</code>によるデーモンへの管理操作依頼コマンドへと移行します。</p>

<p>このスクリプトを<code>datadog-agent</code>のファイル名で<code>/etc/init.d</code>に設置し実行権限を付与します。
<code>bash
cd /etc/init.d
vi datadog-agent # 先の内容をコピペします
chmod 755 datadog-agent
</code></p>

<p><code>datadog-agent</code>の動作の確認をします。</p>

<p>```bash
./datadog-agent start
./datadog-agent stop
./datadog-agent restart</p>

<p>```</p>

<p>最後に、<code>datadog-agent</code>を自動起動スクリプトとして登録します。</p>

<p><code>bash
update-rc.d datadog-agent defaults
</code></p>

<p>ここで、Raspbery Piを再起動します。Raspberry Piが再起動し、sshでアクセスできたら、次のコマンドを実行してみます。</p>

<p><code>bash
sudo su
cd /root/.datadog-agent
sh bin/agent info
</code></p>

<p>Raspberry Piの起動時にDD-Agentが正しく起動していれば、次のように出力されます。</p>

<h1>```bash</h1>

<h1>Collector (v 4.2.1)</h1>

<p>  Status date: 2014-05-13 15:35:31 (11s ago)
  Pid: 2168
  Platform: Linux-3.10.25+-armv6l-with-debian-7.5
  Python Version: 2.7.3
  Logs: <stderr>, syslog:/dev/log</p>

<p>  Clocks
  ======</p>

<pre><code>NTP offset: 0.0006 s
System UTC time: 2014-05-13 06:35:43.754188
</code></pre>

<p>  Paths
  =====</p>

<pre><code>conf.d: /root/.datadog-agent/agent/conf.d
checks.d: /root/.datadog-agent/agent/checks.d
</code></pre>

<p>  Hostnames
  =========</p>

<pre><code>socket-hostname: raspberrypi
ec2-hostname: raspberrypi
hostname: raspberrypi
socket-fqdn: raspberrypi
</code></pre>

<p>  Checks
  ======</p>

<pre><code>network
-------
  - instance #0 [OK]
  - Collected 8 metrics &amp; 0 events
</code></pre>

<p>  Emitters
  ========</p>

<pre><code>- http_emitter [OK]
</code></pre>

<p>===================</p>

<h1>Dogstatsd (v 4.2.1)</h1>

<p>  Status date: 2014-05-13 15:35:44 (0s ago)
  Pid: 2166
  Platform: Linux-3.10.25+-armv6l-with-debian-7.5
  Python Version: 2.7.3
  Logs: <stderr>, syslog:/dev/log</p>

<p>  Flush count: 4391
  Packet Count: 0
  Packets per second: 0.0
  Metric count: 0
  Event count: 0</p>

<p>===================</p>

<h1>Forwarder (v 4.2.1)</h1>

<p>  Status date: 2014-05-13 15:35:45 (1s ago)
  Pid: 2167
  Platform: Linux-3.10.25+-armv6l-with-debian-7.5
  Python Version: 2.7.3
  Logs: <stderr>, syslog:/dev/log</p>

<p>  Queue Size: 0 bytes
  Queue Length: 0
  Flush Count: 2901
  Transactions received: 1395
  Transactions flushed: 1395
```</p>

<p>ここまでできれば、Dogstatsdを使ってGPIOで収集したデータを<a href="http://www.datadoghq.com/">Datadoghq.com</a>へ送信できます。</p>

<p><a href="../../../../../blog/2014/04/11/datadog-on-raspberry-pi-1/">Raspberry piにもDatadog Agentをインストールしてみる(前編)</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Datadogに任意のメトリックスを送信する (その1)]]></title>
    <link href="http://jhotta.github.io/blog/2014/04/24/datadog-sending-custom-metrics-1/"/>
    <updated>2014-04-24T16:53:00+09:00</updated>
    <id>http://jhotta.github.io/blog/2014/04/24/datadog-sending-custom-metrics-1</id>
    <content type="html"><![CDATA[<p>Datadogに任意のメトリックスを継続的に送信するには、DogStatsDを介してDatadogのサイトに送信するのが最も簡単な方法です。</p>

<p><a href="http://docs.datadoghq.com/guides/dogstatsd/">DogStatsD</a>は、NYC発祥の物販サイト<a href="https://www.etsy.com/">Etsy</a>がFOSS化している<a href="https://github.com/etsy/statsd/">StatsD</a>のプロトコルを実装したメトリクス集積サーバ(a metrics aggregation server)です。DogStatsDは、DD-agentに同胞されているので、既にDD-agentが動作していればすぐに使うことができます。(但し、Intel Galileoのようにデーモンを手動で起動するケースは、dogstatsdを起動している必要があります。)</p>

<p><em>StatsD及びStatsDプロトコルは、DevOpsを実践している欧米企業で各種のメトリックスを収集するために広く使われているソフトウェアとプロトコルです。</em></p>

<p><img class="center" src="/images/blog-images/dogstatsd.png" width="800" height="800" title="&lsquo;DogStatsD&rsquo; &lsquo;DogStatsD&rsquo;" ></p>

<p>DogStatsDは、アプリケーションからUDPで受け取ったメトリックスを一旦ホスト内で蓄積します。その後一定時間ことに、DatadogのサイトにHTTPSで送信します。Datagogのサイトでは、DogStatsDから受けとったメトリックスも名前スペースとタグ付によって管理され、他のメトリックスと同様にグラフ化することができるようになっています。</p>

<p>DogStatsDとの通信がなぜUDPかというという事に関しては、「この間の通信の障害や遅延によってアプリケーションの動作をストールさせないため」と書いてありました。</p>

<h3>DogStatsDのラッパーライブラリーについて</h3>

<p>DogStatsDへのメトリックス送信手続きを簡素化するために、一般的な言語向けにラッパーライブラリーが提供されています。これらのラッパーライブラリーを活用すると数行のコード追加で任意メトリックスをDogStatsDに転送することができます。</p>

<p>以下に代表的なライブラリーを紹介しておきます。</p>

<h4>Datadogによって提供されているライブラリー</h4>

<p><strong>Python: </strong>
<a href="https://github.com/DataDog/dogstatsd-python">dogstatsd-python</a> &ndash; Python DogStatsD client.</p>

<p><strong>Ruby: </strong>
<a href="https://github.com/DataDog/dogstatsd-ruby">dogstatsd-ruby</a> &ndash; Ruby DogStatsD client.</p>

<p><strong>PHP: </strong>
<a href="https://github.com/DataDog/php-datadogstatsd">php-datadogstatsd</a> &ndash; PHP DogStatsD client.</p>

<p><strong>C#: </strong>
<a href="https://github.com/DataDog/dogstatsd-csharp-client">dogstatsd-csharp-client</a> &ndash; C# DogStatsD client.</p>

<h4>コミュニティーによって提供されいるライブラリー</h4>

<p><strong>Java: </strong>
<a href="https://github.com/indeedeng/java-dogstatsd-client">java-dogstatsd-client</a> &ndash; DogStatsD Client for Java, <a href="https://github.com/indeedeng">Indeed</a>提供.</p>

<p><strong>Node.js: </strong>
<a href="https://github.com/joybro/node-dogstatsd">node-dogstatsd</a> &ndash; Node.js DogStatsD client, <a href="https://github.com/joybro">Young Han Lee</a>提供.</p>

<p><strong>Perl: </strong>
<a href="https://github.com/zipkid/dogstatsd-perl">dogstatsd-perl</a> &ndash; Perl DogStatsD client, <a href="https://github.com/zipkid">Stefan Goethals</a>提供.</p>

<p><strong>Ruby: </strong>
<a href="https://github.com/mavenlink/metriks-dogstatsd">metricks-dogstatsd</a> &ndash; backend for the popular Metriks gem, <a href="https://github.com/mavenlink">Mavenlink</a>提供.</p>

<p><strong>Go: </strong>
<a href="https://github.com/ooyala/go-dogstatsd/">go-dogstatsd</a> &ndash; dogstatsd client written in Go, <a href="https://github.com/ooyala">Ooyala</a>提供.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Datadog agentをIntel Galileoで動かす(前編)]]></title>
    <link href="http://jhotta.github.io/blog/2014/04/14/datadog-agent-for-intel-galileo-1/"/>
    <updated>2014-04-14T16:54:00+09:00</updated>
    <id>http://jhotta.github.io/blog/2014/04/14/datadog-agent-for-intel-galileo-1</id>
    <content type="html"><![CDATA[<p><img class="right" src="/images/blog-images/intel_galileo.jpg" width="300" height="300" title="&lsquo;intel galileo&rsquo; &lsquo;intel galileo&rsquo;" ></p>

<p>Datadog agent(以後DD-agent)が、Raspberry Piであっさり動いてしまったので、流行のIntel Galileo(以降Galileo)でもあっさり動くのではと思い挑戦してみました。
結果から言うと<strong>「問題なく出来ます」</strong>、しかし、Raspberry Pi(Rasbian)の時のように、Datadogが用意してくれている１行コマンド行を実行すれば完成ということには成りませんでした。</p>

<p>こういう時こそ情報の供給がだいじだと思うのでインストール方法を書き残しておくとにします。尚今回は、DD-agentとDogtatsDを起動させ、メトリックスをDatadogに送信しするところまでの手順を書きます。これらのスクリプトをGalileoの起動時に自動で起動する方法やGPIOからの情報を読み込み送信する方法は、後編で書こうと思います。</p>

<h2>起動用のSDイメージについて</h2>

<p>個人的に利用頻度が最も多い<a href="http://wiki.tokor.org/%20Tokoro's%20Tech-Note">Tokoro&rsquo;s Tech-Note</a>で公開されている<a href="http://storage.tokor.org/pub/galileo/images/full">SDフルイメージ</a>を利用します。</p>

<p>このイメージの特徴は、arduino IDEは使えなくなるものの、linux系のlibでちょっとこれがあると便利かもというものがrepoから簡単に入手できることです。(Tokoro氏の善意に感謝します。)</p>

<p>先の<a href="http://storage.tokor.org/pub/galileo/images/full">SDフルイメージ</a>をPCにダウンロードし解凍後、fat32でフォーマットした4G SDカート(4G以上のSDの場合は、4Gのパーティションを作成してください)に書き込めば、起動用のSDカードの準備は完了です。</p>

<p>以下が解凍した<a href="http://storage.tokor.org/pub/galileo/images/full">SDフルイメージ</a>の中身です。
<img class="center" src="/images/blog-images/SD-full-list.png" width="800" height="800" title="&lsquo;解凍したSDの中身&rsquo; &lsquo;SD full soft list&rsquo;" ></p>

<p>準備ができたSDカードをGalileに差し込んで、LANケーブルと電源を指すと<a href="https://www.yoctoproject.org/%20yocto">Yocto linux</a>が起動してきます。LAN(eth0)は、IP addressを自動で取得する設定に成っているので、Galileoを接続したネットワークにDHCPサーバーが存在している必要があります。IP addressは、OSが起動したのを見計らってIPスキャナー<a href="https://itunes.apple.com/jp/app/lanscan/id472226235?mt=12%20LanSacan">LanScan</a>などでIntel GalileoのMACアドレスを探してIP addressを確認します。MACアドレスの情報は、LANコネクター口の上にシールで張られています。</p>

<p>OSが起動しIP addressが分かったら、sshでGalileoに接続していきます。</p>

<p><code>
$ ssh root@X.X.X.X
</code></p>

<p>rootにはpasswordは設定されてないので、sshの接続手順が完了すると、一気に管理者権限のコンソールが表示されます。</p>

<p><code>
The authenticity of host '192.168.8.171 (192.168.8.171)' can't be established.
RSA key fingerprint is 4d:5e:57:43:b0:02:6e:f3:ae:3c:1e:2c:7a:55:f5:4b.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added 'X.X.X.X' (RSA) to the list of known hosts.
root@clanton:~#
</code></p>

<h2>DD-agent起動に足りないPackageのインストール</h2>

<p>sshで接続ができたところで、まず最初にする作業は、Tokoroさんが提供してくれているPackageをopkgコマンドでインストールするためのrepo情報の追記です。</p>

<p>既にrepo情報が追記された設定ファイルも公開されているので、下記のコマンドを実行して既存のrepo設定ファイルをTokoroさんのrepoの設定情報が記載された設定ファイルに置き換えます。</p>

<p><code>
wget http://storage.tokor.org/pub/galileo/packages/opkg.conf -O /etc/opkg/opkg.conf
</code></p>

<p>詳細に関しては、<a href="http://wiki.tokor.org/index.php?Intel%A4%CEGalileo%A4%C7%A5%D1%A5%C3%A5%B1%A1%BC%A5%B8%A5%DE%A5%CD%A1%BC%A5%B8%A5%E3opkg%A4%F2%BB%C8%A4%A6%A1%A1-%A1%A1Galileo">「IntelのGalileoでパッケージマネージャopkgを使う」</a>を参照してください。</p>

<p>次に、Package情報を更新し、新しいバージョンのパッケージがあるものは最新に入れ替えておくことにします。</p>

<p><code>
opkg update
opkg upgrade
</code></p>

<p>起動時にDateコマンドで毎回時間を設定するのは非常に手間なので、簡単に時間が設定されるようにします。自動で時間を設定してくれるntpdateをPackageインストールします。</p>

<p><code>
opkg install ntpdate
ntpdate ntpdate ntp.nict.jp
</code></p>

<p>次に、ntpdもインストールして設定しておきます。</p>

<p><code>
opkg install ntp
</code></p>

<p>ntpの設定ファイルを編集します。</p>

<p><code>
vi /etc/ntp.conf
</code></p>

<p><em># server time.server.example.com</em>と書かれている行をコメントアウトし、次のように公開されているntpサーバー名を記載します。</p>

<p>```</p>

<h1>server time.server.example.com</h1>

<p>server ntp.nict.jp
server 0.asia.pool.ntp.org
```</p>

<p>次に、システムの状態を定期的に監視するためのsysstatをPackageインストールします。</p>

<p><code>
opkg install sysstat
</code></p>

<p>DD-agentを起動するためのPackageの追加インストールは、これで終了です。</p>

<h2>DD-agentのダウンロード</h2>

<p>OSの準備ができたので、DD-agentをGithubから取得し、Galileoに設置します。
Githubのサイトで、<strong>DD-agent</strong>を検索すると、次のような検索結果が表示されます。</p>

<p><img class="center" src="/images/blog-images/github-dd-agent.png" width="800" height="800" title="&lsquo;github dd-agent&rsquo; &lsquo;github dd-agent&rsquo;" ></p>

<p>赤枠で囲った項目をダブルクリックして、Datadogが管理しているdd-agentのページに移動します。</p>

<p><img class="center" src="/images/blog-images/github-dd-agent-dl.png" width="800" height="800" title="&lsquo;github dd-agent&rsquo; &lsquo;github dd-agent&rsquo;" ></p>

<p><code>Download ZIP</code> ボタンを見つけ、右クリックを使ってリンク先URLをクリップボードに保存ます。</p>

<p>Galileoのwgetコマンドでは、githubのCAの情報がうまく処理でないようなので<em>&mdash;no-check-certificate</em>をコマンドオプションに追記し実行します。</p>

<p><code>
wget --no-check-certificate https://github.com/DataDog/dd-agent/archive/master.zip
</code></p>

<p>ダウンロードが終わったらファイルを解凍し、起動の準備に入ります。</p>

<p><code>
unzip master.zip
</code></p>

<p>master.zipは、<code>dd-agent-master</code>というディレクトリ以下に展開されます。</p>

<p><code>
cd dd-agent-master
</code></p>

<p>ディレクトリを<code>ls</code>で表示してみると次の様になっているはずです。</p>

<p><code>
root@clanton:~/dd-agent-master# ls
CHANGELOG.md    aggregator.py   dogstream  requirements.txt
LICENSE     checks    emitter.py   resources
LICENSE-boto    checks.d    ez_setup.py  setup.py
LICENSE-httplib2  compat    graphite.py  supervisord.dev.conf
LICENSE-minjson   conf.d    httplibproxy.py  tests
LICENSE-ntplib    config.py   jmxfetch.py  transaction.py
MANIFEST.in   daemon.py   migration.py   urllib2proxy.py
README.markdown   datadog-cert.pem  minjson.py   util.py
Rakefile    datadog.conf.example  modules.py   win32
Vagrantfile   ddagent.py    packaging  yaml
agent.py    dogstatsd.py    pup
</code></p>

<h2>API keyの取得</h2>

<p>DatadogのAPIアクセスは、API keyを使って認証しています。このkey(文字列)情報は、DD-agentの起動時に設定ファイルから読み込む仕様になっているので、設置ファイルに事前に記述しておく必要があります。</p>

<p>設定ファイルのサンプルが、dd-agent-masterディレクトリにあるので、このサンプルファイルをコピーして作業を始めます。</p>

<p><code>
cp datadog.conf.example datadog.conf
</code></p>

<p>次に、設定ファイルに書き込むためのAPI keyを<a href="https://app.datadoghq.com/account/settings#api">Datadog APIs</a>ページから取得します。</p>

<p><img class="center" src="/images/blog-images/datadog-apikey.png" width="800" height="800" title="&lsquo;datadog apikey&rsquo; &lsquo;datadog apikey&rsquo;" ></p>

<p>API keyの文字列が分かったところで、設定ファイルの編集をします</p>

<p><code>
vi datadog.conf
</code></p>

<p>設定ファイルの18行目にある、<code>api_key:</code>の後ろに先のページで取得したAPI keyをペーストします。</p>

<p>```
[Main]</p>

<h1>The host of the Datadog intake server to send Agent data to</h1>

<p>dd_url: <a href="https://app.datadoghq.com">https://app.datadoghq.com</a></p>

<h1>If you need a proxy to connect to the Internet, provide the settings here</h1>

<h1>proxy_host: my-proxy.com</h1>

<h1>proxy_port: 3128</h1>

<h1>proxy_user: user</h1>

<h1>proxy_password: password</h1>

<h1>If you run the agent behind haproxy, you might want to set this to yes</h1>

<h1>skip_ssl_validation: no</h1>

<h1>The Datadog api key to associate your Agent&rsquo;s data with your organization.</h1>

<h1>Can be found here:</h1>

<h1><a href="https://app.datadoghq.com/account/settings">https://app.datadoghq.com/account/settings</a></h1>

<p>api_key:
```</p>

<p>これで設定ファイルの追記も完了です。</p>

<h2>Agentの動作確認</h2>

<p>Agentを起動する前にdatadog関連のデーモンがlogを出力する先のディレクトリーを準備しておきます。</p>

<p><code>
mkdir /var/log/datadog
</code></p>

<p>それでは、Agentを起動してみます。</p>

<p><code>
cd ~/dd-agent-master
python agent.py start
</code></p>

<p>しばらくすると、Datadogの<a href="https://app.datadoghq.com/infrastructure">Infrastrucure</a>ページ上に<strong>clanton</strong>(Galileoに設定したホスト名)というホスト名が追加されます。</p>

<p><img class="center" src="/images/blog-images/datadog-infra-clanton.png" width="800" height="800" title="&lsquo;datadog clanton&rsquo; &lsquo;datadog clanton&rsquo;" ></p>

<p>ホスト名をダブルクリックすると、sysstatが収集しているGalileoの基本メトリックスがグラフ化されて表示されるはずです。</p>

<p><img class="center" src="/images/blog-images/datadog-clanton.png" width="800" height="800" title="&lsquo;datadog clanton&rsquo; &lsquo;datadog clanton&rsquo;" ></p>

<h2>DogtatsDの動作確認</h2>

<p>次に、任意のメトリックスを手軽に転送するためにDogStatsを起動することにします。</p>

<p><a href="http://docs.datadoghq.com/guides/dogstatsd/">DogStatsD</a>は、NYC発祥の物販サイト<a href="https://www.etsy.com/">Etsy</a>がFOSS化している<a href="https://github.com/etsy/statsd/">StatsD</a>のプロトコルを利用した派生バージョンです。StatsDは、DevOpsを実践している欧米企業で各種のメトリックスを収集するために広く使われているソフトウェアです。</p>

<p>同様の目的でDogStatsDを使うことで、プログラムの中からDatadogのサービスに任意のメトリックスを簡単に転送することができます。メトリックスさえ転送できてしまえば、後はDatadogのダッシュボード機能を使って、集めたメトリックスをリアルタイムに処理&amp;可視化できるという文脈になります。</p>

<p>既に設定ファイルへのAPI keyの追記は済んでいるので、次のように起動します。</p>

<p><code>
cd ~/dd-agent-master
python dogstatsd.py start
</code></p>

<p>任意のメトリックスをプログラムの中からDogStatsDを介してDatadogに送信ができたかを確認するためには、次のような簡単なプログムを書きます。</p>

<p>pythonの場合は、Datadogが提供しているDogStatsDのラッパーライブラリーがPIPにあるので次のようにインストールすることにします。</p>

<p><code>
cd ~/dd-agent-master
python ez_setup.py
easy_isntall pip
pip install dogstatsd-python
</code></p>

<p>dogstatsd-pythonのインストールが無事インストールが成功したら、<strong>dogstatsd-test.py</strong>などのファイル名で次のファイルのようなpythonスクリプトを書きます。</p>

<p>```python</p>

<h1>! /usr/bin/env python</h1>

<p>from statsd import statsd
import time
import random</p>

<p>def mysleep():</p>

<pre><code>statsd.increment('myapp.testsleep')
sleep_time = random.uniform(0.0, 0.9)
print "sleep: %f" % sleep_time
time.sleep(sleep_time)
</code></pre>

<p>if <strong>name</strong> == &ldquo;<strong>main</strong>&rdquo;:</p>

<pre><code>while(1):
    mysleep();
</code></pre>

<p>```</p>

<p>pythonスクリプトが書き上がったところで実行してみます。</p>

<p><code>
python dogstatsd-test.py
</code></p>

<p>コンソールに大量の<em>sleep</em>文字列が出力されます。バックグラウンドではsleepが表示された回数をカウントして、一定時間ごとにそのカウント値をDatadogに転送しています。</p>

<p>先に見たDatadogの<a href="https://app.datadoghq.com/infrastructure">Infrastrucure</a>ページの<strong>clanton</strong>の行の右端にmyappという青いラベルが増えていることが確認できたら、ダブルクリックしmyappの名前スペースのメトリックスを表示するページに移動します。</p>

<p>今は、myappの名前スペースに１種類のメトリックスしかないので、次のようなグラフが表示されれば、動作確認は完了です。</p>

<p><img class="center" src="/images/blog-images/datadog-myapp-testsleep.png" width="800" height="800" title="&lsquo;datadog myapp testsleep&rsquo; &lsquo;datadog myapp testsleep&rsquo;" ></p>

<h2>まとめ</h2>

<p>ここまでで前編は終わりです。内容が理解できれば30分以内でできてしまうインストール作業ではないかと思います。こんな簡単な作業で、GPIOで集めた情報も可視化できるなんて素晴しいと思いませんか。後半では、GalileoのGPIO関連ライブラリーと任意のメトリックスの取り扱いに関して書いていこうと思います。</p>

<ul>
<li>2014/04/18 ntpdate、及びntpの設定に関連する記述を変更しました。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Datadog Integrationsを追加する]]></title>
    <link href="http://jhotta.github.io/blog/2014/04/14/datadog-integrations/"/>
    <updated>2014-04-14T16:44:00+09:00</updated>
    <id>http://jhotta.github.io/blog/2014/04/14/datadog-integrations</id>
    <content type="html"><![CDATA[<p>DD−agentが収集している基本的なメトリックスのグラフを見ているだけでも多くのことが分るようになりますが、それ以外にもDatadog社が事前に準備してくれているメトリックス収集プラグインが存在しています。これらのプラグインをDatadogでは、Integrationsと読んでいるようです。</p>

<p>Datadogにloginし、ダッシュボードから<code>Integrations</code> タブにカーソルを移動し、ドロップダウンから<code>Integrations</code>を選択すると次のページに移動することができます。</p>

<p><img class="center" src="/images/blog-images/datadog-integrations.png" width="800" height="800" title="&lsquo;datadog integrations&rsquo; &lsquo;datadog integrations&rsquo;" ></p>

<p>各Instarationのタイルにカーソルを合わせると、その解説が表示され、<code>Avalable</code>ボタンが、<code>Install</code>に変わります。<code>Install</code>をダブルクリックする、次のようなインストール確認の画面が表示されます。</p>

<p><img class="center" src="/images/blog-images/datadog-integrations-add.png" width="800" height="800" title="&lsquo;datadog integrations&rsquo; &lsquo;datadog integrations&rsquo;" ></p>

<p>Configurationタブを選択して、設定項目を入力し<code>Install Integration</code>をクリックします。</p>

<p>Integrationの種類によっては、サーバー側の設定が必要なものもあります。その情報は、Configurationページで詳細に記載されています。その手順に従って設定作業を完了しておいてください。</p>

<p>Datadog側でIntagrationのインストールが完了すると、ページ上段のInstalled項目にタイルが表示されます。後に設定の変更などが発生した場合は、緑の<code>Installed</code>ボタンをクリックし、再度<code>Configuration</code>タブ選択し再設定することで、新しい設定を反映させるとことができます。</p>

<p><img class="center" src="/images/blog-images/datadog-integrations-installed.png" width="800" height="800" title="&lsquo;datadog integrations&rsquo; &lsquo;datadog integrations&rsquo;" ></p>

<p>Configurationが正しくできてメトリックスがDatadog側で受信できていれば、しばらくすると<code>Infrastracture</code>ページにメトリックスを表示するための青いラベルが追加されます。</p>
]]></content>
  </entry>
  
</feed>
